{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " # 1.   The number of pages the document has\n",
        " \n"
      ],
      "metadata": {
        "id": "mtsWoLUQziCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To count the number of pages in a text file using the Natural Language Toolkit (nltk), we'll first need to read the text file and then determine the number of pages based on a specific criterion. Here's one way to do this using an assumption of approximately 300 words per page  on text files:\n"
      ],
      "metadata": {
        "id": "JmJ76JCt0Lx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# nltk.download('all')"
      ],
      "metadata": {
        "id": "AqkBlS7JyxU5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrjjCZ8vyYZe",
        "outputId": "a9a4244e-7535-4bb2-d167-68a86adcb775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pages: 3.96\n"
          ]
        }
      ],
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "# Read the text file into a string\n",
        "with open(\"sample2.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Count the number of words\n",
        "word_count = len(words)\n",
        "\n",
        "# Divide the word count by 300 to get the number of pages\n",
        "page_count = word_count / 300\n",
        "\n",
        "print(\"Number of pages:\", page_count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 2. number of paragraphs\n",
        "\n"
      ],
      "metadata": {
        "id": "4V0DOePs0x3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can determine the number of paragraphs based on the separator used to separate paragraphs in the file. assumes the paragraphs are separated by a newline character:"
      ],
      "metadata": {
        "id": "hUk8Wpb01NER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the text into paragraphs using newline as the separator\n",
        "paragraphs = text.split(\"\\n\")\n",
        "\n",
        "# Count the number of paragraphs\n",
        "paragraph_count = len(paragraphs)\n",
        "\n",
        "print(\"Number of paragraphs:\", paragraph_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt0P07jS08Py",
        "outputId": "7b43c91e-6ed4-476f-b7f9-e9e28037c7e4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of paragraphs: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Number of sentences"
      ],
      "metadata": {
        "id": "FkXnma1M1_aN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To count the number of sentences in a text file using the Natural Language Toolkit (nltk), we'll first need to read the text file and then use the sent_tokenize function to split the text into sentences."
      ],
      "metadata": {
        "id": "etJv5Op814Q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize\n",
        "\n",
        "# Tokenize the text into sentences\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Count the number of sentences\n",
        "sentence_count = len(sentences)\n",
        "\n",
        "print(\"Number of sentences:\", sentence_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuET047-2IjH",
        "outputId": "82bebc93-3d0e-44c9-e426-f89bec4d3bbb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Type and number of words"
      ],
      "metadata": {
        "id": "1NaKa_JO-cqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to count the number of words and identify type of words in document we should tokenize it into words, and then use the *FreqDist* class to count the frequency of each word."
      ],
      "metadata": {
        "id": "0Toi6SbgBQIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "\n",
        "from nltk.tokenize import  regexp_tokenize\n",
        "\n",
        "\n",
        "formated_word = regexp_tokenize(text, \"[\\w']+\")\n",
        "\n",
        "# Count the frequency of each word using the FreqDist class\n",
        "fdist_all_document = FreqDist(formated_word)\n",
        "\n",
        "# Print the number of unique types of words and the total number of words\n",
        "print(\"Number of unique types of words:\", len(fdist))\n",
        "print(\"Number of words:\", sum(fdist.values()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9r045Yn-iKI",
        "outputId": "8aef78db-3346-46af-a496-0952cc4af6af"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique types of words: 173\n",
            "Number of words: 1029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Rank of the words based on their freuquency as well as their location (in each paragraph, page, etc)"
      ],
      "metadata": {
        "id": "g8bsjiK-_Ppe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To rank the words based on their frequency and location (in each paragraph, page, etc) in a text file using the Natural Language Toolkit (nltk), we'll first need to read the text file, tokenize it into words, and then use the *FreqDist* class to count the frequency of each word. Then, we can split the text into paragraphs, pages, or any other desired location, and keep track of the word frequency and location for each word."
      ],
      "metadata": {
        "id": "Qo4vikhsBnbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store the word frequency and location for each word\n",
        "word_info = {}\n",
        "\n",
        "# Loop through each paragraph\n",
        "for i, paragraph in enumerate(paragraphs):\n",
        "    # Tokenize the paragraph into words\n",
        "    words_in_paragraph = regexp_tokenize(paragraph, \"[\\w']+\")\n",
        "    \n",
        "    # Count the frequency of each word in the paragraph using the FreqDist class\n",
        "    fdist = FreqDist(words_in_paragraph)\n",
        "    \n",
        "    # Loop through each word and store its frequency and location in the dictionary\n",
        "    for word, freq in fdist.items():\n",
        "        if word in word_info:\n",
        "            word_info[word][\"frequency\"] += freq\n",
        "            word_info[word][\"location\"].append(i+1)\n",
        "        else:\n",
        "            word_info[word] = {\"frequency\": freq, \"location\": [i+1]}\n",
        "\n",
        "# Sort the dictionary based on frequency and store the result in a list\n",
        "word_info_sorted = sorted(word_info.items(), key=lambda x: x[1][\"frequency\"], reverse=True)\n",
        "\n",
        "# Print the first 10 ranked words and their frequency and location\n",
        "for i, (word, info) in enumerate(word_info_sorted[:10]):\n",
        "    print(f\"Rank {i+1}: {word} (Frequency: {info['frequency']}, Location: {info['location']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTUS5Kdz_tLB",
        "outputId": "ca2f3723-1894-42f6-d52f-6c76ae822746"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 1: you (Frequency: 60, Location: [1, 3, 4, 6, 7, 8])\n",
            "Rank 2: the (Frequency: 53, Location: [1, 3, 4, 6, 7, 8, 10])\n",
            "Rank 3: and (Frequency: 39, Location: [1, 3, 4, 6, 7, 8, 9, 10])\n",
            "Rank 4: a (Frequency: 37, Location: [1, 3, 4, 6, 7, 8, 10])\n",
            "Rank 5: to (Frequency: 32, Location: [1, 3, 4, 6, 7, 8])\n",
            "Rank 6: your (Frequency: 28, Location: [1, 3, 4, 6, 7, 8])\n",
            "Rank 7: document (Frequency: 22, Location: [1, 3, 4, 6, 7, 8, 9, 10])\n",
            "Rank 8: click (Frequency: 20, Location: [1, 3, 4, 6, 7, 8])\n",
            "Rank 9: new (Frequency: 20, Location: [1, 3, 4, 6, 7, 8])\n",
            "Rank 10: in (Frequency: 17, Location: [1, 3, 4, 6, 7, 8, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Total frequency and rank of words from the total document\n"
      ],
      "metadata": {
        "id": "is6SIb875DDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the total frequency and rank of words from a text file using the Natural Language Toolkit (nltk), we use the *FreqDist* class to count the frequency of each word. Then, we can sort the words based on their frequency and assign ranks to each word."
      ],
      "metadata": {
        "id": "IxWKBtVN5eWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sort the frequency distribution based on frequency and store the result in a list\n",
        "fdist_sorted = sorted(fdist_all_document.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Assign ranks to each word\n",
        "ranks = {word: rank + 1 for rank, (word, _) in enumerate(fdist_sorted)}\n",
        "\n",
        "# Print the  ranked words and their frequency\n",
        "for i, (word, freq) in enumerate(fdist_sorted):\n",
        "    print(f\"Rank {ranks[word]}: {word} (Frequency: {freq})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvLY6tPl5URG",
        "outputId": "6de3c42b-0c66-458e-c974-fa1efb54046e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank 1: you (Frequency: 60)\n",
            "Rank 2: the (Frequency: 53)\n",
            "Rank 3: and (Frequency: 39)\n",
            "Rank 4: a (Frequency: 37)\n",
            "Rank 5: to (Frequency: 32)\n",
            "Rank 6: your (Frequency: 28)\n",
            "Rank 7: document (Frequency: 22)\n",
            "Rank 8: click (Frequency: 20)\n",
            "Rank 9: new (Frequency: 20)\n",
            "Rank 10: in (Frequency: 17)\n",
            "Rank 11: When (Frequency: 16)\n",
            "Rank 12: can (Frequency: 16)\n",
            "Rank 13: want (Frequency: 16)\n",
            "Rank 14: for (Frequency: 13)\n",
            "Rank 15: add (Frequency: 12)\n",
            "Rank 16: that (Frequency: 12)\n",
            "Rank 17: Word (Frequency: 12)\n",
            "Rank 18: change (Frequency: 12)\n",
            "Rank 19: where (Frequency: 12)\n",
            "Rank 20: on (Frequency: 12)\n",
            "Rank 21: headings (Frequency: 10)\n",
            "Rank 22: text (Frequency: 9)\n",
            "Rank 23: Video (Frequency: 8)\n",
            "Rank 24: provides (Frequency: 8)\n",
            "Rank 25: way (Frequency: 8)\n",
            "Rank 26: help (Frequency: 8)\n",
            "Rank 27: video (Frequency: 8)\n",
            "Rank 28: You (Frequency: 8)\n",
            "Rank 29: also (Frequency: 8)\n",
            "Rank 30: fits (Frequency: 8)\n",
            "Rank 31: To (Frequency: 8)\n",
            "Rank 32: header (Frequency: 8)\n",
            "Rank 33: cover (Frequency: 8)\n",
            "Rank 34: page (Frequency: 8)\n",
            "Rank 35: then (Frequency: 8)\n",
            "Rank 36: choose (Frequency: 8)\n",
            "Rank 37: styles (Frequency: 8)\n",
            "Rank 38: match (Frequency: 8)\n",
            "Rank 39: theme (Frequency: 8)\n",
            "Rank 40: need (Frequency: 8)\n",
            "Rank 41: it (Frequency: 8)\n",
            "Rank 42: Reading (Frequency: 8)\n",
            "Rank 43: is (Frequency: 5)\n",
            "Rank 44: powerful (Frequency: 4)\n",
            "Rank 45: prove (Frequency: 4)\n",
            "Rank 46: point (Frequency: 4)\n",
            "Rank 47: Online (Frequency: 4)\n",
            "Rank 48: paste (Frequency: 4)\n",
            "Rank 49: embed (Frequency: 4)\n",
            "Rank 50: code (Frequency: 4)\n",
            "Rank 51: type (Frequency: 4)\n",
            "Rank 52: keyword (Frequency: 4)\n",
            "Rank 53: search (Frequency: 4)\n",
            "Rank 54: online (Frequency: 4)\n",
            "Rank 55: best (Frequency: 4)\n",
            "Rank 56: make (Frequency: 4)\n",
            "Rank 57: look (Frequency: 4)\n",
            "Rank 58: professionally (Frequency: 4)\n",
            "Rank 59: produced (Frequency: 4)\n",
            "Rank 60: footer (Frequency: 4)\n",
            "Rank 61: box (Frequency: 4)\n",
            "Rank 62: designs (Frequency: 4)\n",
            "Rank 63: complement (Frequency: 4)\n",
            "Rank 64: each (Frequency: 4)\n",
            "Rank 65: other (Frequency: 4)\n",
            "Rank 66: For (Frequency: 4)\n",
            "Rank 67: example (Frequency: 4)\n",
            "Rank 68: matching (Frequency: 4)\n",
            "Rank 69: sidebar (Frequency: 4)\n",
            "Rank 70: Click (Frequency: 4)\n",
            "Rank 71: Insert (Frequency: 4)\n",
            "Rank 72: elements (Frequency: 4)\n",
            "Rank 73: from (Frequency: 4)\n",
            "Rank 74: different (Frequency: 4)\n",
            "Rank 75: galleries (Frequency: 4)\n",
            "Rank 76: Themes (Frequency: 4)\n",
            "Rank 77: keep (Frequency: 4)\n",
            "Rank 78: coordinated (Frequency: 4)\n",
            "Rank 79: Design (Frequency: 4)\n",
            "Rank 80: Theme (Frequency: 4)\n",
            "Rank 81: pictures (Frequency: 4)\n",
            "Rank 82: charts (Frequency: 4)\n",
            "Rank 83: SmartArt (Frequency: 4)\n",
            "Rank 84: graphics (Frequency: 4)\n",
            "Rank 85: apply (Frequency: 4)\n",
            "Rank 86: Save (Frequency: 4)\n",
            "Rank 87: time (Frequency: 4)\n",
            "Rank 88: with (Frequency: 4)\n",
            "Rank 89: buttons (Frequency: 4)\n",
            "Rank 90: show (Frequency: 4)\n",
            "Rank 91: up (Frequency: 4)\n",
            "Rank 92: them (Frequency: 4)\n",
            "Rank 93: picture (Frequency: 4)\n",
            "Rank 94: button (Frequency: 4)\n",
            "Rank 95: layout (Frequency: 4)\n",
            "Rank 96: options (Frequency: 4)\n",
            "Rank 97: appears (Frequency: 4)\n",
            "Rank 98: next (Frequency: 4)\n",
            "Rank 99: work (Frequency: 4)\n",
            "Rank 100: table (Frequency: 4)\n",
            "Rank 101: row (Frequency: 4)\n",
            "Rank 102: or (Frequency: 4)\n",
            "Rank 103: column (Frequency: 4)\n",
            "Rank 104: plus (Frequency: 4)\n",
            "Rank 105: sign (Frequency: 4)\n",
            "Rank 106: easier (Frequency: 4)\n",
            "Rank 107: too (Frequency: 4)\n",
            "Rank 108: view (Frequency: 4)\n",
            "Rank 109: collapse (Frequency: 4)\n",
            "Rank 110: parts (Frequency: 4)\n",
            "Rank 111: of (Frequency: 4)\n",
            "Rank 112: focus (Frequency: 4)\n",
            "Rank 113: If (Frequency: 4)\n",
            "Rank 114: stop (Frequency: 4)\n",
            "Rank 115: reading (Frequency: 4)\n",
            "Rank 116: before (Frequency: 4)\n",
            "Rank 117: reach (Frequency: 4)\n",
            "Rank 118: end (Frequency: 4)\n",
            "Rank 119: remembers (Frequency: 4)\n",
            "Rank 120: left (Frequency: 4)\n",
            "Rank 121: off (Frequency: 4)\n",
            "Rank 122: even (Frequency: 4)\n",
            "Rank 123: another (Frequency: 4)\n",
            "Rank 124: device (Frequency: 4)\n",
            "Rank 125: are (Frequency: 3)\n",
            "Rank 126: section (Frequency: 3)\n",
            "Rank 127: level (Frequency: 3)\n",
            "Rank 128: using (Frequency: 2)\n",
            "Rank 129: such (Frequency: 2)\n",
            "Rank 130: as (Frequency: 2)\n",
            "Rank 131: The (Frequency: 2)\n",
            "Rank 132: Table (Frequency: 2)\n",
            "Rank 133: This (Frequency: 1)\n",
            "Rank 134: was (Frequency: 1)\n",
            "Rank 135: created (Frequency: 1)\n",
            "Rank 136: accessibility (Frequency: 1)\n",
            "Rank 137: techniques (Frequency: 1)\n",
            "Rank 138: lists (Frequency: 1)\n",
            "Rank 139: image (Frequency: 1)\n",
            "Rank 140: alternate (Frequency: 1)\n",
            "Rank 141: tables (Frequency: 1)\n",
            "Rank 142: columns (Frequency: 1)\n",
            "Rank 143: It (Frequency: 1)\n",
            "Rank 144: should (Frequency: 1)\n",
            "Rank 145: be (Frequency: 1)\n",
            "Rank 146: completely (Frequency: 1)\n",
            "Rank 147: accessible (Frequency: 1)\n",
            "Rank 148: assistive (Frequency: 1)\n",
            "Rank 149: technologies (Frequency: 1)\n",
            "Rank 150: screen (Frequency: 1)\n",
            "Rank 151: readers (Frequency: 1)\n",
            "Rank 152: There (Frequency: 1)\n",
            "Rank 153: eight (Frequency: 1)\n",
            "Rank 154: this (Frequency: 1)\n",
            "Rank 155: At (Frequency: 1)\n",
            "Rank 156: beginning (Frequency: 1)\n",
            "Rank 157: Sample (Frequency: 1)\n",
            "Rank 158: Document (Frequency: 1)\n",
            "Rank 159: 1 (Frequency: 1)\n",
            "Rank 160: heading (Frequency: 1)\n",
            "Rank 161: main (Frequency: 1)\n",
            "Rank 162: Headings (Frequency: 1)\n",
            "Rank 163: Lists (Frequency: 1)\n",
            "Rank 164: 2 (Frequency: 1)\n",
            "Rank 165: Tables (Frequency: 1)\n",
            "Rank 166: contains (Frequency: 1)\n",
            "Rank 167: two (Frequency: 1)\n",
            "Rank 168: sub (Frequency: 1)\n",
            "Rank 169: Simple (Frequency: 1)\n",
            "Rank 170: Complex (Frequency: 1)\n",
            "Rank 171: which (Frequency: 1)\n",
            "Rank 172: both (Frequency: 1)\n",
            "Rank 173: 3 (Frequency: 1)\n"
          ]
        }
      ]
    }
  ]
}